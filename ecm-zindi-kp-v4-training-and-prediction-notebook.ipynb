{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "050531cb",
   "metadata": {
    "papermill": {
     "duration": 0.012319,
     "end_time": "2023-10-12T11:48:50.586844",
     "exception": false,
     "start_time": "2023-10-12T11:48:50.574525",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !pip install --upgrade plotly plotnine\n",
    "# !pip install fastinference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d83b08b0",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "papermill": {
     "duration": 5.676727,
     "end_time": "2023-10-12T11:48:56.268296",
     "exception": false,
     "start_time": "2023-10-12T11:48:50.591569",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import random\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "from fastai.tabular.all import * \n",
    "# from fastinference.tabular import *\n",
    "from sklearn.model_selection import GroupKFold\n",
    "from sklearn.metrics import mean_absolute_error, mean_absolute_percentage_error\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler, SplineTransformer\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import Adam, SGD\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import TensorDataset, DataLoader,Dataset\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau, CosineAnnealingWarmRestarts\n",
    "\n",
    "warnings.simplefilter(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "71e42b23",
   "metadata": {
    "papermill": {
     "duration": 0.020674,
     "end_time": "2023-10-12T11:48:56.294191",
     "exception": false,
     "start_time": "2023-10-12T11:48:56.273517",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def periodic_spline_transformer(period, n_splines=None, degree=3):\n",
    "    if n_splines is None:\n",
    "        n_splines = period\n",
    "    n_knots = n_splines + 1  # periodic and include_bias is True\n",
    "    return SplineTransformer(\n",
    "        degree=degree,\n",
    "        n_knots=n_knots,\n",
    "        knots=np.linspace(0, period, n_knots).reshape(n_knots, 1),\n",
    "        extrapolation=\"periodic\",\n",
    "        include_bias=True)\n",
    "\n",
    "def seed_everything(seed=42):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "#     os.environ['CUDA_LAUNCH_BLOCKING'] = str(1)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "set_seed(42)\n",
    "seed_everything(seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fbdaa52e",
   "metadata": {
    "papermill": {
     "duration": 1.364575,
     "end_time": "2023-10-12T11:48:57.663500",
     "exception": false,
     "start_time": "2023-10-12T11:48:56.298925",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/kaggle/input/ecm-itu-zindi-kp-data/imgs_2023071012133740345.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m set_seed(\u001b[38;5;241m42\u001b[39m)\n\u001b[1;32m      2\u001b[0m seed_everything(seed\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n\u001b[0;32m----> 4\u001b[0m df_train \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/kaggle/input/ecm-itu-zindi-kp-data/imgs_2023071012133740345.csv\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mparse_dates\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mTime\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m df_test \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/kaggle/input/ecm-itu-zindi-kp-data/imgs_202307101549519358.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m,parse_dates\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTime\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m      6\u001b[0m df_cell \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/kaggle/input/ecm-itu-zindi-kp-data/imgs_2023071012130978799.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m,parse_dates\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTime\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m   1014\u001b[0m     dialect,\n\u001b[1;32m   1015\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m   1023\u001b[0m )\n\u001b[1;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pandas/io/parsers/readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    617\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    619\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 620\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1617\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1619\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1880\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1879\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1880\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1881\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1882\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1883\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1884\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1885\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1886\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1887\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1888\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1889\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1890\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1891\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pandas/io/common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    869\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    870\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    871\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    872\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    874\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    875\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    876\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    877\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    878\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    879\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/kaggle/input/ecm-itu-zindi-kp-data/imgs_2023071012133740345.csv'"
     ]
    }
   ],
   "source": [
    "set_seed(42)\n",
    "seed_everything(seed=42)\n",
    "\n",
    "df_train = pd.read_csv(\"/kaggle/input/ecm-itu-zindi-kp-data/imgs_2023071012133740345.csv\",parse_dates=['Time'])\n",
    "df_test = pd.read_csv(\"/kaggle/input/ecm-itu-zindi-kp-data/imgs_202307101549519358.csv\",parse_dates=['Time'])\n",
    "df_cell = pd.read_csv(\"/kaggle/input/ecm-itu-zindi-kp-data/imgs_2023071012130978799.csv\",parse_dates=['Time'])\n",
    "df_bs = pd.read_csv(\"/kaggle/input/ecm-itu-zindi-kp-data/imgs_2023071012123392536.csv\")\n",
    "df_features = df_cell.merge(df_bs,on=['BS','CellName'],how='outer')\n",
    "df_features = df_features[df_features['CellName']=='Cell0'].reset_index(drop=True)\n",
    "df_test['split'] = 'test'\n",
    "df_train['split'] = 'train'\n",
    "df_total = pd.concat([df_train,df_test],ignore_index=True)\n",
    "df_total = df_total.merge(df_features,on=['BS','Time'],how='left')\n",
    "df_total['ID'] = df_total['Time'].astype(str)+\"_\"+df_total['BS']\n",
    "df_total['BS'] = df_total['BS'].str.replace(r'[a-zA-Z_]', '', regex=True).astype(int)\n",
    "for col in ['RUType','Mode']:\n",
    "    df_total[col] = df_total[col].str.replace(r'[a-zA-Z]', '', regex=True).astype(int)\n",
    "\n",
    "df_total.sort_values(['BS','Time'], ascending=True,ignore_index=True,inplace=True)\n",
    "df_total['day'] = df_total['Time'].dt.day\n",
    "df_total['weekday_number'] = df_total['Time'].dt.weekday\n",
    "df_total['hour'] = df_total['Time'].dt.hour\n",
    "\n",
    "hour_df = df_total[['hour']].copy()\n",
    "splines = periodic_spline_transformer(24, n_splines=12).fit_transform(hour_df)\n",
    "splines_df = pd.DataFrame(splines,columns=[f\"hour_spline_{i}\" for i in range(splines.shape[1])])\n",
    "df_total = pd.concat([df_total,splines_df],axis=1)\n",
    "\n",
    "df_total = df_total.sort_values(['BS','Time'],ascending=True,ignore_index=True)\n",
    "all_shits = list(np.arange(1,4)) # \n",
    "for shift_i in tqdm(all_shits):\n",
    "    for col in ['load','ESMode1','ESMode2','ESMode3','ESMode6','Time','Energy']:\n",
    "        df_total[f'{col}_T-{shift_i}'] = df_total.groupby(['BS'])[col].shift(shift_i)        \n",
    "for shift_i in tqdm(all_shits):\n",
    "    df_total[f'Time_T-{shift_i}_hours_elapsed'] = (df_total[f'Time_T-{shift_i}']-df_total['Time']).dt.total_seconds() / 3600\n",
    "    del df_total[f'Time_T-{shift_i}']\n",
    "print(df_total.shape)\n",
    "\n",
    "num_bins = 100\n",
    "df_total['load_bin'] = pd.cut(df_total['load'],bins=[round(i,2) for i in list(np.arange(0,1.01,0.01))],labels=[f'{i}' for i in range(num_bins)])\n",
    "df_total['load_bin'] = df_total['load_bin'].astype(float).fillna(-1).astype(int)\n",
    "\n",
    "print(df_total.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73ae4f4e",
   "metadata": {
    "papermill": {
     "duration": 0.563225,
     "end_time": "2023-10-12T11:48:58.231945",
     "exception": false,
     "start_time": "2023-10-12T11:48:57.668720",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "sns.displot(df_total['Energy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d44ca917",
   "metadata": {
    "papermill": {
     "duration": 0.268094,
     "end_time": "2023-10-12T11:48:58.505511",
     "exception": false,
     "start_time": "2023-10-12T11:48:58.237417",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_total.groupby(['Time'])[['Energy']].mean().plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce67b176",
   "metadata": {
    "papermill": {
     "duration": 0.661038,
     "end_time": "2023-10-12T11:48:59.172802",
     "exception": false,
     "start_time": "2023-10-12T11:48:58.511764",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_total.groupby(['load'])[[\"Energy\"]].mean().plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e443bb02",
   "metadata": {
    "papermill": {
     "duration": 11.450701,
     "end_time": "2023-10-12T11:49:10.630693",
     "exception": false,
     "start_time": "2023-10-12T11:48:59.179992",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "set_seed(42)\n",
    "seed_everything(seed=42)\n",
    "\n",
    "from scipy.signal import savgol_filter as sg\n",
    "from scipy.signal import sosfiltfilt, butter, sosfilt, sosfilt_zi\n",
    "\n",
    "def add_sg(df):\n",
    "    w = 5 #5\n",
    "    p = 3 #2\n",
    "    for si in tqdm(df.BS.unique()):\n",
    "        index = df.BS == si\n",
    "        df.loc[index, 'load_smooth'] = sg(df[index].load, w, p)\n",
    "        df.loc[index, 'load_diff'] = sg(df[index].load, w, p, 1)\n",
    "        df.loc[index, 'load_diff2'] = sg(df[index].load, w, p, 2)\n",
    "        df.loc[index, 'load_diff3'] = sg(df[index].load, w, p, 3)\n",
    "\n",
    "add_sg(df_total)\n",
    "print(df_total.shape)\n",
    "\n",
    "def add_sosfiltfilt(df):\n",
    "    for si in tqdm(df.BS.unique()):\n",
    "        index = df.BS == si\n",
    "        sos=butter(4, 0.125, output='sos')\n",
    "        sos8 = butter(8, 0.125, output='sos')\n",
    "        zi = np.array(df[index].load[:4]).mean() * sosfilt_zi(sos8)\n",
    "        df.loc[index, 'load_sosfiltfilt'] = sosfiltfilt(sos,df[index].load)\n",
    "        df.loc[index, 'load_sosfilt'], _ = sosfilt(sos8, df[index].load, zi=zi)\n",
    "\n",
    "add_sosfiltfilt(df_total)\n",
    "print(df_total.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "970f297e",
   "metadata": {
    "papermill": {
     "duration": 0.176732,
     "end_time": "2023-10-12T11:49:10.819189",
     "exception": false,
     "start_time": "2023-10-12T11:49:10.642457",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "set_seed(42)\n",
    "seed_everything(seed=42)\n",
    "\n",
    "df_total.drop(columns=['w','CellName','ESMode4','Time'],inplace=True)\n",
    "\n",
    "id_variable = 'ID'\n",
    "version_nb = 'v4'\n",
    "TARGET = 'Energy'\n",
    "\n",
    "train_df = df_total[df_total['split']=='train'].reset_index(drop=True)\n",
    "test_df = df_total[df_total['split']=='test'].reset_index(drop=True)\n",
    "train_cols = [i for i in train_df if i not in ['Time','CellName','ID','Energy','split','w','BS','ESMode6']]\n",
    "\n",
    "categorical_cols = ['RUType','Mode','load_bin']\n",
    "\n",
    "print(train_df[train_cols].shape, test_df[train_cols].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9ba0895",
   "metadata": {
    "papermill": {
     "duration": 0.130431,
     "end_time": "2023-10-12T11:49:10.961947",
     "exception": false,
     "start_time": "2023-10-12T11:49:10.831516",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "set_seed(42)\n",
    "seed_everything(seed=42)\n",
    "\n",
    "remove_non_unique_cols = []\n",
    "print('train single values ..')\n",
    "for col in train_df:\n",
    "    if col in train_cols and col not in ['ESMode5']:\n",
    "        if train_df[col].nunique()<=1:\n",
    "            remove_non_unique_cols.append(col)\n",
    "            print(col,\":\",train_df[col].nunique())\n",
    "print('test single values ..')\n",
    "for col in test_df:\n",
    "    if col in train_cols and col not in ['ESMode5']:\n",
    "        if test_df[col].nunique()<=1:\n",
    "            remove_non_unique_cols.append(col)\n",
    "            print(col,\":\",test_df[col].nunique())\n",
    "\n",
    "print('\\n',remove_non_unique_cols)\n",
    "\n",
    "for col in train_df:\n",
    "    if col in train_cols:\n",
    "        if train_df[col].isnull().sum()/len(train_df)>=0.95:\n",
    "            print(col,\":\",train_df[col].isnull().sum()/len(train_df))\n",
    "            remove_non_unique_cols.append(col)\n",
    "\n",
    "for col in test_df:\n",
    "    if col in train_cols:\n",
    "        if test_df[col].isnull().sum()/len(test_df)>=0.95:\n",
    "            print(col,\":\",test_df[col].isnull().sum()/len(test_df))\n",
    "            remove_non_unique_cols.append(col)\n",
    "            \n",
    "print(len(train_cols))\n",
    "train_cols = [col for col in train_cols if col not in remove_non_unique_cols]\n",
    "print(len(train_cols))\n",
    "print(train_cols)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cb52cf9",
   "metadata": {
    "papermill": {
     "duration": 0.03948,
     "end_time": "2023-10-12T11:49:11.014197",
     "exception": false,
     "start_time": "2023-10-12T11:49:10.974717",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "set_seed(42)\n",
    "seed_everything(seed=42)\n",
    "\n",
    "Nfold = 10\n",
    "Inference=False\n",
    "\n",
    "if Inference:\n",
    "    print('Data has been splitted...')\n",
    "else:\n",
    "    train_df['fold'] = 0\n",
    "    strafy_bin = train_df['BS'].astype('int')\n",
    "\n",
    "    skf = GroupKFold(n_splits = Nfold)\n",
    "    for i, (_, train_index) in enumerate(skf.split(train_df.index,train_df.index, strafy_bin)):\n",
    "        train_df.loc[train_index, 'fold'] = i  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49944ca9",
   "metadata": {
    "papermill": {
     "duration": 0.011295,
     "end_time": "2023-10-12T11:49:11.037638",
     "exception": false,
     "start_time": "2023-10-12T11:49:11.026343",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### FastAI model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cc2c861",
   "metadata": {
    "papermill": {
     "duration": 0.029383,
     "end_time": "2023-10-12T11:49:11.079035",
     "exception": false,
     "start_time": "2023-10-12T11:49:11.049652",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "set_seed(42)\n",
    "seed_everything(seed=42)\n",
    "\n",
    "def mae(preds, targs):\n",
    "    x = (targs-preds)\n",
    "    return (abs(x)).mean()\n",
    "\n",
    "def mape(preds, targs):\n",
    "    x = (targs-preds)/targs\n",
    "    return (abs(x)).mean()\n",
    "\n",
    "def fit_fastai(Nfolds, train_df, test_df, train_cols, cat_feats, TARGET, model_path):\n",
    "    \n",
    "    oof_pred_fastai = np.zeros(train_df.shape[0], dtype=np.float32)\n",
    "    pred_fastai = np.zeros(test_df.shape[0], dtype=np.float32)\n",
    "    scores = []\n",
    "    scores_pvt = []\n",
    "    \n",
    "    train_df_fast = train_df[train_cols + [TARGET]].copy()\n",
    "    test_df = test_df.copy()\n",
    "    for col in train_df_fast.columns:\n",
    "        if col not in cat_feats:\n",
    "            train_df_fast[col] = train_df_fast[col].fillna(0)\n",
    "            test_df[col] = test_df[col].fillna(0)\n",
    "        else:\n",
    "            # Impute missing categorical values with the most frequent category\n",
    "            most_frequent_category = train_df_fast[col].mode().iloc[0]\n",
    "            train_df_fast[col] = train_df_fast[col].fillna(most_frequent_category)\n",
    "            test_df[col] = test_df[col].fillna(most_frequent_category)\n",
    "\n",
    "    train_df_fast[cat_feats] = train_df_fast[cat_feats].astype('category')\n",
    "    test_df[cat_feats] = test_df[cat_feats].astype('category')\n",
    "    \n",
    "    cont_nn = train_cols.copy()\n",
    "    for col in cat_feats:\n",
    "        cont_nn.remove(col)\n",
    "\n",
    "    cat_nn = cat_feats\n",
    "\n",
    "    layers =  [256, 512, 1024, 512, 256] #[256, 512, 1024, 512, 256]\n",
    "\n",
    "    val_pct, tst_preds = L(), L()\n",
    "\n",
    "    for fold in range(Nfolds):\n",
    "        print(\"*\"*10, f'Fold-{fold+1}', \"*\"*10)\n",
    "        train_idx = train_df.loc[train_df['fold']!=fold, :].index\n",
    "        valid_idx = train_df.loc[train_df['fold']==fold, :].index\n",
    "        splits = (L(list(train_idx)), L(list(valid_idx)))\n",
    "        dls = TabularPandas(train_df_fast, [Categorify, Normalize], cat_nn, cont_nn, splits = splits, y_names=TARGET,reduce_memory=False).dataloaders(1024)\n",
    "        learn = tabular_learner(dls, layers=layers, n_out=1, y_range = (0,100),loss_func = mae, metrics=AccumMetric(mae))\n",
    "#         print(learn.summary())\n",
    "#         learn.lr_find(suggest_funcs=(slide, valley))\n",
    "#         if os.path.isfile(model_path + f'models/nn_model_{fold}.pth'):\n",
    "#             learn = tabular_learner(dls, layers=layers, n_out=1, path = model_path)\n",
    "#             learn.load(f'nn_model_{fold}')\n",
    "#         else:\n",
    "        learn.fit_one_cycle(100, 2e-3, cbs=SaveModelCallback(monitor='mae', comp=np.less, fname=f'nn_model_{fold}'))\n",
    "\n",
    "        val_df = train_df.loc[train_df['fold']==fold]\n",
    "        val_dl = dls.test_dl(val_df[train_cols].fillna(0))\n",
    "        \n",
    "        preds, _ = learn.get_preds(dl=val_dl)\n",
    "        oof_pred_fastai[val_df.index] = preds.squeeze().numpy()\n",
    "       \n",
    "        score = mean_absolute_error(val_df[TARGET], oof_pred_fastai[val_df.index])\n",
    "        score_pvt = mean_absolute_percentage_error(val_df[TARGET], oof_pred_fastai[val_df.index])\n",
    "        \n",
    "        scores.append(score)\n",
    "        scores_pvt.append(score_pvt)\n",
    "        print(f'MAE for Fold-{fold+1}:', np.round(score, 3))\n",
    "        print(f'MAPE for Fold-{fold+1}:', np.round(score_pvt, 3))\n",
    "        \n",
    "        test_dl = dls.test_dl(test_df[train_cols])\n",
    "        preds, _ = learn.get_preds(dl=test_dl)\n",
    "        pred_fastai += preds.squeeze().numpy()/Nfolds\n",
    "\n",
    "#         display(test_df[train_cols].iloc[-5:])\n",
    "        \n",
    "#         exp = ShapInterpretation(learn, test_df[train_cols].iloc[-5:])\n",
    "#         exp.summary_plot()\n",
    "\n",
    "\n",
    "    score = mean_absolute_error(train_df[TARGET],oof_pred_fastai)\n",
    "    score_pvt = mean_absolute_percentage_error(train_df[TARGET],oof_pred_fastai)\n",
    "    \n",
    "    print(f'OOF MAE:', np.round(score, 3))\n",
    "    print(f'Average MAE:', f'{np.round(np.mean(scores), 3)}+/-{np.round(np.std(scores), 3)}')\n",
    "    \n",
    "    print(f'OOF MAPE:', np.round(score_pvt, 3))\n",
    "    print(f'Average MAPE:', f'{np.round(np.mean(scores_pvt), 3)}+/-{np.round(np.std(scores_pvt), 3)}')\n",
    "\n",
    "    return oof_pred_fastai, pred_fastai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2b3b33e",
   "metadata": {
    "papermill": {
     "duration": 1008.822813,
     "end_time": "2023-10-12T12:05:59.912892",
     "exception": false,
     "start_time": "2023-10-12T11:49:11.090079",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "set_seed(42)\n",
    "seed_everything(seed=42)\n",
    "\n",
    "if Inference:\n",
    "    model_path = '../input/ecm-output-of-final-notebook/'\n",
    "else:\n",
    "    model_path = './'\n",
    "\n",
    "oof_pred_fastai, pred_fastai = fit_fastai(Nfold, train_df, test_df, train_cols, categorical_cols, TARGET, model_path)\n",
    "\n",
    "train_df = train_df.copy()\n",
    "train_df['oof_fastai'] = oof_pred_fastai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ee6323e",
   "metadata": {
    "papermill": {
     "duration": 0.099767,
     "end_time": "2023-10-12T12:06:00.046655",
     "exception": false,
     "start_time": "2023-10-12T12:05:59.946888",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "set_seed(42)\n",
    "seed_everything(seed=42)\n",
    "\n",
    "submission_fastai = pd.DataFrame(data = {'Time': test_df['ID'].values, 'Energy': pred_fastai})\n",
    "print(submission_fastai.head())\n",
    "submission_fastai.to_csv(f'submission_fastai.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7b9d051",
   "metadata": {
    "papermill": {
     "duration": 0.040723,
     "end_time": "2023-10-12T12:06:00.120898",
     "exception": false,
     "start_time": "2023-10-12T12:06:00.080175",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# OOF MAE: 0.686\n",
    "# Average MAE: 0.686+/-0.048\n",
    "# OOF MAPE: 0.027\n",
    "# Average MAPE: 0.027+/-0.003"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bae2d8ae",
   "metadata": {
    "papermill": {
     "duration": 0.032334,
     "end_time": "2023-10-12T12:06:00.186156",
     "exception": false,
     "start_time": "2023-10-12T12:06:00.153822",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Keras Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc41f070",
   "metadata": {
    "papermill": {
     "duration": 8.568898,
     "end_time": "2023-10-12T12:06:08.787938",
     "exception": false,
     "start_time": "2023-10-12T12:06:00.219040",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from keras import backend as K\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow import keras\n",
    "from keras import backend as K\n",
    "from keras.backend import sigmoid\n",
    "from tensorflow.keras.utils import get_custom_objects\n",
    "from keras.layers import Activation\n",
    "from keras.backend import sigmoid\n",
    "from keras import backend as K\n",
    "\n",
    "set_seed(42)\n",
    "seed_everything(seed=42)\n",
    "tf.random.set_seed(42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7917e6c7",
   "metadata": {
    "papermill": {
     "duration": 0.053512,
     "end_time": "2023-10-12T12:06:08.875277",
     "exception": false,
     "start_time": "2023-10-12T12:06:08.821765",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "set_seed(42)\n",
    "seed_everything(seed=42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "def mean_absolute_error(y_true, y_pred):\n",
    "         return K.mean(K.abs( (y_true - y_pred)))\n",
    "\n",
    "es = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss', patience=50, verbose=0,\n",
    "    mode='min',restore_best_weights=True)\n",
    "\n",
    "plateau = tf.keras.callbacks.ReduceLROnPlateau(\n",
    "    monitor='val_loss', factor=0.25, patience=8, verbose=0,\n",
    "    mode='min')\n",
    "\n",
    "def swish(x, beta = 1):\n",
    "    return (x * sigmoid(beta * x))\n",
    "\n",
    "def mish(x, beta = 1):\n",
    "    return (x * K.tanh(K.softplus(x)))\n",
    "\n",
    "\n",
    "get_custom_objects().update({'swish': Activation(swish)})\n",
    "get_custom_objects().update({'mish': Activation(mish)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8b965e1",
   "metadata": {
    "papermill": {
     "duration": 0.043103,
     "end_time": "2023-10-12T12:06:08.951232",
     "exception": false,
     "start_time": "2023-10-12T12:06:08.908129",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "set_seed(42)\n",
    "seed_everything(seed=42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "def base_model(hidden_units, embedding_size, train_cols, \n",
    "               categorical_cols, uniques):\n",
    "\n",
    "    n_cont=0\n",
    "    initial_inputs=[]\n",
    "    for col in categorical_cols:\n",
    "        temp_input = keras.Input(shape=(1,), name=col)\n",
    "        n_cont+=1\n",
    "        initial_inputs.append(temp_input)\n",
    "        \n",
    "    num_input = keras.Input(shape=(len(train_cols)-n_cont,), name='num_data')\n",
    "    initial_inputs.append(num_input)\n",
    "\n",
    "    #embedding, flatenning and concatenating\n",
    "    all_inputs=[]\n",
    "    for i, col in enumerate(categorical_cols):\n",
    "        temp_embedded = keras.layers.Embedding(int(uniques[col]), embedding_size, \n",
    "                                               input_length=1, name=f'{col}_embedding')(initial_inputs[i])\n",
    "        temp_flattened = keras.layers.Flatten()(temp_embedded)\n",
    "        all_inputs.append(temp_flattened)\n",
    "    \n",
    "    all_inputs.append(num_input)\n",
    "    out = keras.layers.Concatenate()(all_inputs)\n",
    "    \n",
    "    # Add one or more hidden layers\n",
    "    for n_hidden in hidden_units:\n",
    "        out = keras.layers.Dense(n_hidden, activation='swish')(out)\n",
    "\n",
    "    # A single output: our predicted rating\n",
    "    out = keras.layers.Dense(1, activation='linear', name='prediction')(out)\n",
    "\n",
    "    model = keras.Model(inputs = initial_inputs, outputs = out)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9db379bf",
   "metadata": {
    "papermill": {
     "duration": 0.052968,
     "end_time": "2023-10-12T12:06:09.037231",
     "exception": false,
     "start_time": "2023-10-12T12:06:08.984263",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "set_seed(42)\n",
    "seed_everything(seed=42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "def fit_keras_nn(Nfolds, train_df, test_df, train_cols, cat_cols, TARGET, \n",
    "                   model_path):\n",
    "    \n",
    "    model_name = 'Keras_NN'\n",
    "    oof_keras = np.zeros(train_df.shape[0])\n",
    "    pred_keras = np.zeros(test_df.shape[0])\n",
    "    scores=[]\n",
    "    scores_pvt = []\n",
    "    \n",
    "    train_df = train_df.copy()\n",
    "    test_df = test_df.copy()\n",
    "    train_df = train_df.fillna(0)\n",
    "    test_df = test_df.fillna(0)\n",
    "    \n",
    "    cont_cols = train_cols.copy()\n",
    "    uniques={}\n",
    "    for col in cat_cols:\n",
    "        cont_cols.remove(col)\n",
    "        le = LabelEncoder()\n",
    "        le.fit(pd.concat([train_df[col], test_df[col]]))\n",
    "        train_df[col] = le.transform(train_df[col].values)\n",
    "        test_df[col] = le.transform(test_df[col].values)\n",
    "        uniques[col] = len(pd.concat([train_df[col], test_df[col]], axis=0).unique())\n",
    "        \n",
    "    scaler = StandardScaler().fit(pd.concat([train_df[cont_cols], test_df[cont_cols]], axis=0))       \n",
    "    train_df[cont_cols] = scaler.transform(train_df[cont_cols].values)\n",
    "    test_df[cont_cols] = scaler.transform(test_df[cont_cols].values)\n",
    "    \n",
    "    test_inputs=[]\n",
    "    for col in cat_cols:\n",
    "        test_inputs.append(test_df[col].values)\n",
    "        \n",
    "    test_inputs.append(test_df[cont_cols].values)\n",
    "    \n",
    "    for fold in range(Nfolds):\n",
    "        \n",
    "        print(\"*\"*10, f'Fold-{fold+1}', \"*\"*10,)\n",
    "      \n",
    "        X_train = train_df.loc[train_df.fold!=fold, train_cols]\n",
    "        y_train = train_df.loc[train_df.fold!=fold, TARGET]\n",
    "        X_val = train_df.loc[train_df.fold==fold, train_cols]\n",
    "        y_val = train_df.loc[train_df.fold==fold, TARGET]\n",
    "        \n",
    "        model = base_model(hidden_units=(256, 512, 1024, 512, 256), embedding_size=16, #16\n",
    "                           train_cols=train_cols, categorical_cols=cat_cols, \n",
    "                          uniques=uniques)\n",
    "    \n",
    "        model.compile(\n",
    "            keras.optimizers.Adam(learning_rate=0.002),\n",
    "            loss=mean_absolute_error\n",
    "        )\n",
    "\n",
    "\n",
    "        train_inputs=[]\n",
    "        for col in cat_cols:\n",
    "            train_inputs.append(X_train[col].values)\n",
    "    \n",
    "        train_inputs.append(X_train[cont_cols].values)\n",
    "\n",
    "        val_inputs=[]\n",
    "        for col in cat_cols:\n",
    "            val_inputs.append(X_val[col].values)\n",
    "\n",
    "        val_inputs.append(X_val[cont_cols].values)\n",
    "        \n",
    "#         if os.path.isfile(model_path + f'{model_name}_{fold}.h5'):\n",
    "#             model =  keras.models.load_model(model_path + f'{model_name}_{fold}.h5', \n",
    "#                                              custom_objects={'swish': swish, 'Activation': Activation, \n",
    "#                                                              'mean_absolute_error':mean_absolute_error})\n",
    "        \n",
    "#         else:\n",
    "\n",
    "        model.fit(train_inputs, \n",
    "                  y_train.values,               \n",
    "                  batch_size=1024,\n",
    "                  epochs=1000,\n",
    "                  validation_data=(val_inputs, y_val.values),\n",
    "                  callbacks=[es, plateau],\n",
    "                  validation_batch_size=len(y_val),\n",
    "                  shuffle=True, verbose = 1)\n",
    "\n",
    "        model.save(f\"{model_name}_{fold}.h5\")\n",
    "            \n",
    "        preds = model.predict(val_inputs).reshape(1,-1)[0]\n",
    "        \n",
    "        score = mean_absolute_error(y_val.values, preds)\n",
    "        score_pvt = mean_absolute_percentage_error(y_val.values, preds)\n",
    "        scores.append(score)\n",
    "        scores_pvt.append(score_pvt)\n",
    "        oof_keras[X_val.index] = preds\n",
    "        \n",
    "        print(f'MAE for Fold-{fold+1}:', np.round(score, 3))\n",
    "        print(f'MAPE for Fold-{fold+1}:', np.round(score_pvt, 3))\n",
    "        \n",
    "        pred_keras += model.predict(test_inputs).reshape(1,-1)[0]/Nfolds\n",
    "        \n",
    "    score = mean_absolute_error(train_df[TARGET],oof_keras)\n",
    "    score_pvt = mean_absolute_percentage_error(train_df[TARGET],oof_keras)\n",
    "    print(f'OOF MAE:', np.round(score, 3))\n",
    "    print(f'Average MAE:', f'{np.round(np.mean(scores), 3)}+/-{np.round(np.std(scores), 3)}')\n",
    "    print(f'OOF MAPE:', np.round(score_pvt, 3))\n",
    "    print(f'Average MAPE:', f'{np.round(np.mean(scores_pvt), 3)}+/-{np.round(np.std(scores_pvt), 3)}')\n",
    "    \n",
    "        \n",
    "    return oof_keras, pred_keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7fe9117",
   "metadata": {
    "papermill": {
     "duration": 907.127569,
     "end_time": "2023-10-12T12:21:16.205130",
     "exception": false,
     "start_time": "2023-10-12T12:06:09.077561",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "set_seed(42)\n",
    "seed_everything(seed=42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "if Inference:\n",
    "    model_path = '../input/ecm-output-of-final-notebook/'\n",
    "else:\n",
    "    model_path = './'\n",
    "    \n",
    "oof_pred_keras, pred_keras = fit_keras_nn(Nfold, train_df, test_df, train_cols, categorical_cols, TARGET, model_path)\n",
    "train_df = train_df.copy()\n",
    "train_df['oof_keras'] = oof_pred_keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ed759d0",
   "metadata": {
    "papermill": {
     "duration": 0.960877,
     "end_time": "2023-10-12T12:21:17.989280",
     "exception": false,
     "start_time": "2023-10-12T12:21:17.028403",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "set_seed(42)\n",
    "seed_everything(seed=42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "submission_keras = pd.DataFrame(data = {'Time': test_df['ID'].values, 'Energy': pred_keras})\n",
    "print(submission_keras.head())\n",
    "submission_keras.to_csv('submission_keras.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e84400f",
   "metadata": {
    "papermill": {
     "duration": 0.831547,
     "end_time": "2023-10-12T12:21:19.568673",
     "exception": false,
     "start_time": "2023-10-12T12:21:18.737126",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# OOF MAE: 0.668\n",
    "# Average MAE: 0.668+/-0.052\n",
    "# OOF MAPE: 0.025\n",
    "# Average MAPE: 0.025+/-0.003"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd72f782",
   "metadata": {
    "papermill": {
     "duration": 0.809726,
     "end_time": "2023-10-12T12:21:21.134295",
     "exception": false,
     "start_time": "2023-10-12T12:21:20.324569",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Writing output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dca7f4a",
   "metadata": {
    "papermill": {
     "duration": 0.976645,
     "end_time": "2023-10-12T12:21:22.921664",
     "exception": false,
     "start_time": "2023-10-12T12:21:21.945019",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "set_seed(42)\n",
    "seed_everything(seed=42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "w1_fastai = 0.5\n",
    "w1_keras = 0.5\n",
    "new_pred_ens = train_df['oof_keras']*w1_keras + train_df['oof_fastai']*w1_fastai \n",
    "new_pred_ens_hm = (2*train_df['oof_keras']*train_df['oof_fastai'])/(train_df['oof_keras']+train_df['oof_fastai'])\n",
    "print(f'OOF MAE ENSEMBLE: {mean_absolute_error(train_df.Energy, new_pred_ens)}')\n",
    "print(f'OOF MAPE ENSEMBLE: {mean_absolute_percentage_error(train_df.Energy, new_pred_ens)}')\n",
    "\n",
    "print(f'OOF MAE ENSEMBLE HM: {mean_absolute_error(train_df.Energy, new_pred_ens_hm)}')\n",
    "print(f'OOF MAPE ENSEMBLE HM: {mean_absolute_percentage_error(train_df.Energy, new_pred_ens_hm)}')\n",
    "\n",
    "new_test_pred_ens = pred_keras*w1_keras + pred_fastai*w1_fastai\n",
    "new_test_pred_ens_hm = (2*pred_keras*pred_fastai)/(pred_keras+pred_fastai)\n",
    "\n",
    "submission_ensemble = pd.DataFrame(data = {'Time': test_df['ID'].values, 'Energy': new_test_pred_ens})\n",
    "print(submission_ensemble.head())\n",
    "submission_ensemble.to_csv('submission_ensemble.csv', index=False)\n",
    "\n",
    "submission_ensemble_hm = pd.DataFrame(data = {'Time': test_df['ID'].values, 'Energy': new_test_pred_ens_hm})\n",
    "print(submission_ensemble_hm.head())\n",
    "submission_ensemble_hm.to_csv('submission_ensemble_hm.csv', index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "552eaa4b",
   "metadata": {
    "papermill": {
     "duration": 0.817359,
     "end_time": "2023-10-12T12:21:24.504798",
     "exception": false,
     "start_time": "2023-10-12T12:21:23.687439",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abb90533",
   "metadata": {
    "papermill": {
     "duration": 0.753373,
     "end_time": "2023-10-12T12:21:26.144813",
     "exception": false,
     "start_time": "2023-10-12T12:21:25.391440",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47462474",
   "metadata": {
    "papermill": {
     "duration": 0.757423,
     "end_time": "2023-10-12T12:21:27.708529",
     "exception": false,
     "start_time": "2023-10-12T12:21:26.951106",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 1964.570467,
   "end_time": "2023-10-12T12:21:32.098865",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-10-12T11:48:47.528398",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
